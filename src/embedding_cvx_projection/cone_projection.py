import cvxpy as cp
import numpy as np

BETA = 0.1
SOLVER = cp.SCS
UPPER_BOUND = 1.0  # value between 0 and 1.0. 1.0 means no upper bound.


def cone_projection(
        M: np.ndarray,
        v: np.ndarray,
        beta: float = BETA,
        solver: str = SOLVER,
        upper_bound: float = UPPER_BOUND
) -> tuple[float, np.ndarray]:
    """
    Cone projection problem: finds the closest point to v in the cone generated by the columns of M.
    "closest" is defined in terms of cosine similarity.

    It is intended to be used to find the projection of an embedding onto the cone generated by the embeddings in M.
    That can be used to find the combination of embeddings in M that best approximates v.

    Mathematically:
    min_x -v^T M x + beta * sum(x)
    s.t. ||Mx||_2 <= 1
                x >= 0
                x <= upper_bound * sum(x)

    :param M: (np.ndarray): Each column is an embedding.
    :param v: (np.ndarray): Input embedding vector.
    :param beta: (float, optional): Regularization parameter. Default is BETA.
    :param solver: see https://www.cvxpy.org/tutorial/advanced/index.html#choosing-a-solver. Default is in SOLVER.
    :param upper_bound: (float, optional): Value between 0 and 1.0. 1.0 means no upper bound. Default is UPPER_BOUND.
    :return: Objective value and solution vector
    """

    # Define and solve the CVXPY problem.
    # as many variables as the number of columns of M
    x = cp.Variable(M.shape[1])

    # constraints
    constraints = [
        # the vector M@x (the mixture of the columns of M by the coefficients x) has norm less or equal to 1
        cp.norm2(M @ x) <= 1.0
        ,
        # non-negative coefficients
        x >= 0
    ]

    if upper_bound < 1.0:
        # A single coefficient cannot contain more than upper_bound of the total mixture coefficients.
        # Constraint only added if upper_bound is non-trivial, as it is computationally expensive.
        constraints.append(x <= upper_bound * cp.sum(x))

    prob = cp.Problem(
        # maximize the cosine similarity between v and M @ x
        cp.Minimize(
            -v.T @ M @ x +
            # subject to norm1 regularization
            beta * cp.sum(x)
        )
        , constraints

    )
    prob.solve(solver=solver)

    return -prob.value, x.value


def non_negative_least_squares(
        M: np.ndarray,
        v: np.ndarray,
        beta: float = BETA,
        solver: str = SOLVER
) -> tuple[float, np.ndarray]:
    # Define and solve the CVXPY problem.
    # as many variables as the number of columns of M
    x = cp.Variable(M.shape[1])

    # constraints
    constraints = [
        # non-negative coefficients
        x >= 0
    ]

    prob = cp.Problem(

        # minimize the squared error between v and M @ x
        cp.Minimize(
            cp.sum_squares(v - M @ x) +
            # subject to norm1 regularization
            beta * cp.norm1(x)
        )
        , constraints
    )
    prob.solve(solver=solver)

    return -prob.value, x.value
